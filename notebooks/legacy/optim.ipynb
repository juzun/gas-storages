{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from gas_stor_opt.gas_storage_optim.gs_optim import GasStorage\n",
    "from gas_stor_opt.snowflake_conn import (\n",
    "    download_curve_from_snowflake,\n",
    "    establish_snowflake_connector,\n",
    "    prepare_curve_from_snowflake,\n",
    ")\n",
    "from gas_stor_opt.utils import (\n",
    "    check_for_duplicate_storage_names,\n",
    "    import_prices,\n",
    "    initialize_storage,\n",
    ")\n",
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import datetime\n",
    "import gas_stor_opt.config as config\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import snowflake.connector\n",
    "\n",
    "\n",
    "def establish_snowflake_connector(\n",
    "    account: Optional[str] = config.SNFL_ACCOUNT,\n",
    "    user: Optional[str] = config.SNFL_USER,\n",
    "    password: Optional[str] = config.SNFL_PASSWORD,\n",
    ") -> snowflake.connector.SnowflakeConnection:\n",
    "    snowflake_connector = snowflake.connector.connect(\n",
    "        account=account, user=user, password=password\n",
    "    )\n",
    "    snowflake_connector.cursor()\n",
    "    return snowflake_connector\n",
    "\n",
    "\n",
    "def download_curve_from_snowflake(\n",
    "    snowflake_connector: snowflake.connector.SnowflakeConnection,\n",
    "    price_date: datetime.date,\n",
    "    price_curve_id: Optional[str] = \"GAS_EON_CZVTP_PFC_EOD_D_MID_FINAL\",\n",
    ") -> pd.DataFrame:\n",
    "    query = f\"\"\"\n",
    "    SELECT TIME, VALUE, PRICEDATE from\n",
    "    \"Q_EEDP\".\"DP_PRICE\".\"PRICE_SERIES\"\n",
    "    WHERE PRICECURVEID = '{price_curve_id}' and\n",
    "    PRICEDATE = CAST(DATEFROMPARTS({price_date.year}, {price_date.month}, {price_date.day}) as DATE)\n",
    "    ORDER BY PRICEDATE DESC, TIME ASC\n",
    "    \"\"\"\n",
    "    curve = pd.read_sql_query(query, con=snowflake_connector)\n",
    "    return curve\n",
    "\n",
    "\n",
    "def prepare_curve_from_snowflake(raw_snowflake_table: pd.DataFrame) -> pd.DataFrame:\n",
    "    curve = raw_snowflake_table.rename(columns={\"VALUE\": \"price\", \"TIME\": \"date\"})[\n",
    "        [\"date\", \"price\"]\n",
    "    ]\n",
    "    curve[\"date\"] = pd.to_datetime(curve[\"date\"], utc=True).dt.tz_convert(\n",
    "        tz=pytz.timezone(\"Europe/Prague\")\n",
    "    )\n",
    "    curve = (\n",
    "        curve.set_index(keys=\"date\", drop=True, inplace=False)\n",
    "        .resample(rule=\"MS\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    curve[\"date\"] = curve[\"date\"].apply(lambda x: x.replace(tzinfo=None))\n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gas_stor_opt.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "SNFL_ACCOUNT = os.getenv(\"SNFL_ACCOUNT\")\n",
    "SNFL_USER = os.getenv(\"SNFL_USER\")\n",
    "SNFL_PASSWORD = os.getenv(\"SNFL_PASSWORD\")\n",
    "account = config.SNFL_ACCOUNT\n",
    "user = config.SNFL_USER\n",
    "password = config.SNFL_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_connector = snowflake.connector.connect(\n",
    "    account=account, user=user, password=password\n",
    ")\n",
    "snowflake_connector.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_connector = establish_snowflake_connector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = import_prices(uploaded_file=\"../gas_stor_opt/data/prices1.xlsx\")\n",
    "with open(\"../gas_stor_opt/data/storages.json\", \"r\") as file:\n",
    "    # with open(\"app/src/data/storages.json\", \"r\") as file:  # for Docker build\n",
    "    storages_json = json.load(file)\n",
    "storage_json = storages_json[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stor_name = \"pokus\"\n",
    "date_start = dt.date(2024, 4, 1)\n",
    "date_end = dt.date(2025, 3, 31)\n",
    "initial_state = 0\n",
    "empty_on_end_date = True\n",
    "optimization_time_limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stor_name = \"pokus\"\n",
    "date_start = dt.date(2024, 4, 1)\n",
    "date_end = dt.date(2025, 3, 31)\n",
    "initial_state = 0\n",
    "empty_on_end_date = True\n",
    "optimization_time_limit = None\n",
    "\n",
    "storage = GasStorage(name=stor_name, date_start=date_start, date_end=date_end)\n",
    "storage.load_prices(prices)\n",
    "for period in storage_json[\"TimePeriods\"]:\n",
    "    period_start_date = dt.datetime.strptime(period[\"StartDate\"], \"%Y-%m-%d\").date()\n",
    "    period_end_date = dt.datetime.strptime(period[\"EndDate\"], \"%Y-%m-%d\").date()\n",
    "    if period_end_date >= date_start:\n",
    "        storage.load_attribute(\"wgv\", period[\"WGV\"], period_start_date, period_end_date)\n",
    "        storage.load_attribute(\n",
    "            \"wr\", period[\"WithdrawalRate\"], period_start_date, period_end_date\n",
    "        )\n",
    "        storage.load_attribute(\n",
    "            \"ir\", period[\"InjectionRate\"], period_start_date, period_end_date\n",
    "        )\n",
    "storage.load_attribute(\n",
    "    \"inj_curve\",\n",
    "    np.array(storage_json[\"InjectionCurve\"]) / 100,\n",
    "    date_start,\n",
    "    date_end,\n",
    ")\n",
    "storage.load_attribute(\n",
    "    \"wit_curve\",\n",
    "    np.array(storage_json[\"WithdrawalCurve\"]) / 100,\n",
    "    date_start,\n",
    "    date_end,\n",
    ")\n",
    "storage.set_initial_state(initial_state)\n",
    "storage.set_injection_season(storage_json[\"InjectionSeason\"])\n",
    "storage.set_state_to_date(\n",
    "    {int(key): val for key, val in storage_json[\"StatesToDate\"].items()}\n",
    ")\n",
    "dates_to_empty_storage = []\n",
    "for date in storage_json[\"DatesToEmptyStorage\"]:\n",
    "    dates_to_empty_storage.append(dt.datetime.strptime(date, \"%Y-%m-%d\").date())\n",
    "if empty_on_end_date:\n",
    "    dates_to_empty_storage.append(date_end)\n",
    "storage.set_dates_to_empty_storage(dates_to_empty_storage)\n",
    "if optimization_time_limit is not None:\n",
    "    storage.set_optimization_time_limit(optimization_time_limit)\n",
    "else:\n",
    "    storage.set_optimization_time_limit(storage_json[\"DefaultTimeLimit\"])\n",
    "\n",
    "storage.create_model()\n",
    "storage.solve_model(solver_name=\"scip\", stream_solver=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.read_excel(\n",
    "    \"./gas_stor_opt/data/prices1.xlsx\", usecols=[\"date\", \"price\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.read_excel(\n",
    "    \"./gas_stor_opt/data/prices1.xlsx\",\n",
    "    parse_dates=True,\n",
    "    usecols=\"A:B\",\n",
    "    names=[\"date\", \"price\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.read_excel(\n",
    "    \"./gas_stor_opt/data/zasobniky.xlsx\", usecols=\"A:B\", names=[\"date\", \"price\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.read_excel(\n",
    "    \"./gas_stor_opt/data/prices1.xlsx\", usecols=\"A:B\", names=[\"date\", \"price\"]\n",
    ")\n",
    "dates = pd.to_datetime(excel_file[\"date\"], errors=\"coerce\", format=\"%d-%m-%Y\")\n",
    "excel_file[\"date\"] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prices(imported_prices):\n",
    "    prices_monthly = imported_prices[\n",
    "        imported_prices[\"date\"] >= pd.to_datetime(dt.date(2024, 2, 1).replace(day=1))\n",
    "    ]\n",
    "    prices_monthly[\"year\"] = prices_monthly.loc[:, \"date\"].dt.year\n",
    "    prices_monthly[\"month\"] = prices_monthly.loc[:, \"date\"].dt.month\n",
    "    # attr[\"prices\"] = (\n",
    "    #     pd.merge(attr, prices_monthly, on=[\"year\", \"month\"])\n",
    "    #     .sort_values([\"year\", \"month\"])[\"price\"]\n",
    "    #     .values\n",
    "    # )\n",
    "    return prices_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_prices(imported_prices=excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "\n",
    "dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msal_streamlit_authentication import msal_authentication\n",
    "\n",
    "\n",
    "msal_authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "storages_json = json.load(open(\"./gas_stor_opt/data/storages.json\"))\n",
    "\n",
    "dt.datetime.strptime(\n",
    "    storages_json[\"RWE\"][\"TimePeriods\"][0][\"EndDate\"], \"%Y-%m-%d\"\n",
    ").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storages_json[\"RWE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in storages_json:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(storages_json[1][\"TimePeriods\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storages_json[1][\"TimePeriods\"][1][\"EndDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "\n",
    "# Acquire a credential object\n",
    "credential = DefaultAzureCredential(exclude_environment_credential=True)\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=\"https://datqadl01.blob.core.windows.net\", credential=credential\n",
    ")\n",
    "\n",
    "# Get a client to interact with the container\n",
    "container_name = \"data-lake\"\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "blob_client = container_client.get_blob_client(\n",
    "    \"curated/business-managed/cz/portfolio-management/storages.json\"\n",
    ")\n",
    "with open(\"jsonfile.json\", \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a client to interact with the container\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "\n",
    "DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "\n",
    "# Azure AD service principal details\n",
    "tenant_id = \"XXX\"\n",
    "client_id = \"XXX\"\n",
    "client_secret = \"XXX\"\n",
    "\n",
    "# Azure Data Lake Storage details\n",
    "storage_account_name = \"datqadl01\"\n",
    "container_name = \"data-lake\"\n",
    "\n",
    "# Authenticate using service principal\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=tenant_id, client_id=client_id, client_secret=client_secret\n",
    ")\n",
    "\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{storage_account_name}.blob.core.windows.net\",\n",
    "    credential=credential,\n",
    ")\n",
    "\n",
    "# Get a client to interact with the container\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Now you can perform operations like uploading, downloading files from the container, etc.\n",
    "\n",
    "blob_client = container_client.get_blob_client(\n",
    "    \"curated/business-managed/cz/portfolio-management/storages.json\"\n",
    ")\n",
    "with open(\"jsonfile.json\", \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "\n",
    "storage_account_name = \"datqadl01\"\n",
    "container_name = \"data-lake\"\n",
    "token_credential = DefaultAzureCredential(token=login_token)\n",
    "\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{storage_account_name}.blob.core.windows.net\",\n",
    "    credential=token_credential,\n",
    ")\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blob_client = container_client.get_blob_client(\n",
    "    \"curated/business-managed/cz/portfolio-management/storages.json\"\n",
    ")\n",
    "# blob_client = container_client.get_blob_client(\"curated/gdm/eon/spot/de/pwr/2020/06/25/SpotPrice_PWR_DE_EPEXPeak_d_09_20_20200625.json\")\n",
    "\n",
    "with open(\"jsonfile.json\", \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
