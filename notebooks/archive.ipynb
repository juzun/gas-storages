{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------\n",
    "# # 0. Parameters\n",
    "# # -------------------------------\n",
    "# N = 10000  # number of paths\n",
    "# T = 3\n",
    "# mu, rho, sigma = 10, 0.0, 2  # i.i.d. prices\n",
    "# inventory_levels = [0, 1]  # toy storage\n",
    "# actions = {\n",
    "#     0: [0, +1],  # I=0 can hold or inject\n",
    "#     1: [0, -1],  # I=1 can hold or withdraw\n",
    "# }\n",
    "\n",
    "# # -------------------------------\n",
    "# # 1. Simulate price paths\n",
    "# # -------------------------------\n",
    "# S1 = mu + sigma * np.random.randn(N)\n",
    "# S2 = mu + sigma * np.random.randn(N)\n",
    "# S3 = mu + sigma * np.random.randn(N)\n",
    "\n",
    "# # Store prices in a matrix for easier indexing\n",
    "# S = np.column_stack([S1, S2, S3])\n",
    "\n",
    "# # -------------------------------\n",
    "# # 2. Terminal value\n",
    "# # -------------------------------\n",
    "# # For each inventory state\n",
    "# V = {}\n",
    "# for I in inventory_levels:\n",
    "#     V[(T, I)] = I * S[:, T-1]  # terminal payoff\n",
    "\n",
    "# # -------------------------------\n",
    "# # 3. Backward induction: t=T-1 to 1\n",
    "# # -------------------------------\n",
    "# for t in reversed(range(1, T)):\n",
    "#     V_new = {}\n",
    "#     for I in inventory_levels:\n",
    "#         # For each path, compute value for each possible action\n",
    "#         Q_all_actions = np.zeros((N, len(actions[I])))\n",
    "#         for idx, a in enumerate(actions[I]):\n",
    "#             # check bounds (I+a in allowed inventory)\n",
    "#             if 0 <= I + a <= 1:\n",
    "#                 # cashflow today: inject= -S, withdraw=+S, hold=0\n",
    "#                 CF = np.where(a==+1, -S[:, t-1], 0) + np.where(a==-1, S[:, t-1], 0)\n",
    "#                 # continuation value from next step\n",
    "#                 V_next = V[(t+1, I+a)]\n",
    "#                 Q_all_actions[:, idx] = CF + V_next\n",
    "#             else:\n",
    "#                 Q_all_actions[:, idx] = -np.inf  # illegal action\n",
    "#         # choose optimal action pathwise\n",
    "#         V_new[I] = np.max(Q_all_actions, axis=1)\n",
    "#     V.update({(t, I): V_new[I] for I in inventory_levels})\n",
    "\n",
    "# # -------------------------------\n",
    "# # 4. Storage value at t=1, I=0\n",
    "# # -------------------------------\n",
    "# V1_0 = V[(1, 0)]\n",
    "# storage_value = np.mean(V1_0)\n",
    "# print(\"Storage value at t=1, I=0:\", storage_value)\n",
    "\n",
    "# # -------------------------------\n",
    "# # 5. Reconstruct optimal policy for plot\n",
    "# # -------------------------------\n",
    "# optimal_actions = {}\n",
    "# for t in range(1, T):\n",
    "#     actions_taken = np.zeros(N)\n",
    "#     for I in inventory_levels:\n",
    "#         Q_all_actions = np.zeros((N, len(actions[I])))\n",
    "#         for idx, a in enumerate(actions[I]):\n",
    "#             if 0 <= I + a <= 1:\n",
    "#                 CF = np.where(a==+1, -S[:, t-1], 0) + np.where(a==-1, S[:, t-1], 0)\n",
    "#                 V_next = V[(t+1, I+a)]\n",
    "#                 Q_all_actions[:, idx] = CF + V_next\n",
    "#             else:\n",
    "#                 Q_all_actions[:, idx] = -np.inf\n",
    "#         # best action pathwise\n",
    "#         best_idx = np.argmax(Q_all_actions, axis=1)\n",
    "#         actions_taken[:] = np.array([actions[I][i] for i in best_idx])\n",
    "#     optimal_actions[t] = actions_taken\n",
    "\n",
    "# # -------------------------------\n",
    "# # 6. Plot one path of inventory and actions\n",
    "# # -------------------------------\n",
    "# path = 100  # just pick first path\n",
    "# inventory_path = [0]\n",
    "# for t in range(1, T):\n",
    "#     a = optimal_actions[t][path]\n",
    "#     inventory_path.append(inventory_path[-1]+a)\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.step(range(T), inventory_path, where='post', label='Inventory')\n",
    "# plt.scatter(range(1, T), [optimal_actions[t][path] for t in range(1, T)], \n",
    "#             color='red', label='Action (inject=+1, withdraw=-1)')\n",
    "# plt.xticks(range(T))\n",
    "# plt.xlabel('Time step')\n",
    "# plt.ylabel('Inventory / Action')\n",
    "# plt.title('Toy Storage: Optimal Inventory and Actions (path 0)')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I_max = 100.0\n",
    "# q_in = 5.0\n",
    "# q_out = 5.0\n",
    "\n",
    "# n_I = 51\n",
    "# I_grid = np.linspace(0.0, I_max, n_I)\n",
    "\n",
    "\n",
    "# n_paths, n_steps = paths.shape\n",
    "\n",
    "# V = np.zeros((n_paths, n_I))\n",
    "# S_T = paths[:, -1]\n",
    "\n",
    "# for i, I in enumerate(I_grid):\n",
    "#     V[:, i] = I * S_T\n",
    "\n",
    "# actions = np.array([-q_out, 0.0, q_in])\n",
    "\n",
    "# def continuation_value(S, Y):\n",
    "#     # regress Y on [1, S, S^2]\n",
    "#     X = np.column_stack([np.ones_like(S), S, S**2])\n",
    "#     beta, _, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n",
    "#     return X @ beta\n",
    "\n",
    "# for t in reversed(range(n_steps - 1)):\n",
    "#     print(t)\n",
    "#     S_t = paths[:, t]\n",
    "#     V_next = V.copy()\n",
    "\n",
    "#     for i, I in enumerate(I_grid):\n",
    "#         values = []\n",
    "\n",
    "#         for a in actions:\n",
    "#             I_new = I + a\n",
    "#             if I_new < 0 or I_new > I_max:\n",
    "#                 values.append(np.full_like(S_t, -np.inf))\n",
    "#                 continue\n",
    "\n",
    "#             j = np.argmin(np.abs(I_grid - I_new))\n",
    "\n",
    "#             cont = continuation_value(S_t, V_next[:, j])\n",
    "#             payoff = -a * S_t + cont\n",
    "#             values.append(payoff)\n",
    "\n",
    "#         V[:, i] = np.max(np.column_stack(values), axis=1)\n",
    "\n",
    "\n",
    "# I0 = 50.0\n",
    "# i0 = np.argmin(np.abs(I_grid - I0))\n",
    "\n",
    "# storage_value = V[:, i0].mean()\n",
    "# print(f\"Estimated storage value: {storage_value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
